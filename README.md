# ETL-Polars
ETL process with Polars. DataFrames (tables) are obtain from csv files.

## ðŸŒŽ Repository Structure
```
ETL-Polars/
â”œâ”€â”€ main.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ env/                # Virtual enviroment (not provided)
â””â”€â”€ requirements.txt
â””â”€â”€ pkg                 # Contains all needed files (Python package)
    â””â”€â”€ __init__.py     # Specifies that folder 'pkg' is a Python package
    â””â”€â”€ extract.py      # Contains all functions related to extraction process
    â””â”€â”€ transform.py    # Contains all functions related to transform process
    â””â”€â”€ globals.py      # Contains all global variables
    â””â”€â”€ config.py       # Contains all configuration params
    â””â”€â”€ .env            # Contains all secret data (not provided)
```


## âœ¨ Details

**main.py:** This script calls 'extract.py' to obtain the DataFrames corresponding to the tables, then 'transform.py' script is called to clean data, to convert the columns into the correct format and to load to SQL Server.

## ðŸš€ How to run locally
1. Clone this repository:
```
git clone https://github.com/departamentoIA/ETL-Polars.git
```
2. Set virtual environment and install dependencies.

For Windows:
```
python -m venv env
env/Scripts/activate
pip install -r requirements.txt
```
For Linux:
```
python -m venv env && source env/bin/activate && pip install -r requirements.txt
```
3. Create your ".env" file, which has the following form:
```
DB_SERVER=10.0.00.00,5000
DB_NAME=SAT
DB_USER=caarteaga
DB_PASSWORD=pa$$word
```
4. Run "main.py".